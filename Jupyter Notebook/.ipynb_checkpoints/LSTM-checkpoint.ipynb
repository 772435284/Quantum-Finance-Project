{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libiray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data_save = 'CNN_Pred/'\n",
    "origin_data_save = 'TS_data/'\n",
    "model_save = 'lstm_model_save/'\n",
    "header = ['Open Price', 'High', 'Low', 'Close']\n",
    "window_size = 4      \n",
    "pred_days = 1      \n",
    "\n",
    "# Network Parameters\n",
    "LSTM_input_dim = 4        \n",
    "LSTM_output_dim = 2       \n",
    "n_layers = 2         \n",
    "n_hidden_size = 64   \n",
    "\n",
    "# Hyper parameters\n",
    "EPOCH = 1500        \n",
    "train_ratio = 0.8\n",
    "LR = 1e-2 #Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9094634 , 0.9125382 , 0.90548056, 0.90901625],\n",
       "       [0.90289366, 0.9061216 , 0.89917237, 0.9027511 ],\n",
       "       [0.905483  , 0.9086966 , 0.90171885, 0.905323  ],\n",
       "       ...,\n",
       "       [0.7137139 , 0.7168654 , 0.7111266 , 0.7142442 ],\n",
       "       [0.7131185 , 0.7163243 , 0.7105553 , 0.713661  ],\n",
       "       [0.71819025, 0.7213686 , 0.7156482 , 0.71872145]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data processed by CNN\n",
    "product = 'AUDUSD'\n",
    "ts_d = pd.read_csv(ts_data_save+product+'.csv')\n",
    "\n",
    "\n",
    "ts_d = ts_d.dropna(axis=0,how='any')\n",
    "\n",
    "# Minimize the first three days\n",
    "ts_d_len = len(ts_d) - window_size+1\n",
    "print(ts_d_len)\n",
    "# data.shape: (len(ts_w)*4*4) \n",
    "data = np.zeros((len(ts_d), window_size, LSTM_input_dim), dtype=float)\n",
    "\n",
    "ts_d_n = ts_d.iloc[:,:].values\n",
    "ts_d_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Loading........\n",
      "training data: 1597\n"
     ]
    }
   ],
   "source": [
    "# Generate Traing set\n",
    "for i in range(0, ts_d_len):\n",
    "    # Generate 4*4 temporary array\n",
    "    temp = np.zeros((window_size, LSTM_input_dim))\n",
    "    for j in range(i, i+window_size):\n",
    "        # i=0, j=0,1,2,3 \n",
    "        temp[j-i]=ts_d_n[j]\n",
    "    # Fill data array\n",
    "    data[i] = temp\n",
    "\n",
    "train_num = ts_d_len\n",
    "train_data = data[0:train_num]\n",
    "# Initialize the training matrices\n",
    "train_X = np.zeros((train_num, window_size-pred_days, LSTM_input_dim), dtype=float)\n",
    "train_Y = np.zeros((train_num, LSTM_output_dim), dtype=float)\n",
    "# Split 4*4 data into 3*4 and 1*2\n",
    "for i in range(train_num):\n",
    "    train_X[i] = train_data[i][0:window_size-1]\n",
    "    for j in range(LSTM_output_dim):\n",
    "        train_Y[i][j] = train_data[i][window_size-1][j+1]\n",
    "\n",
    "# Encapsulate the data into torch tensor\n",
    "train_X = torch.tensor(train_X,dtype=torch.float32).cuda()\n",
    "train_Y = torch.tensor(train_Y,dtype=torch.float32).cuda()\n",
    "\n",
    "print('Finish Loading........')\n",
    "print('training data:',train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.91307, 0.91366, 0.89976, 0.903  ],\n",
       "       [0.903  , 0.90761, 0.9002 , 0.90641],\n",
       "       [0.9064 , 0.91164, 0.89889, 0.9101 ],\n",
       "       ...,\n",
       "       [0.64233, 0.64755, 0.64163, 0.64399],\n",
       "       [0.64398, 0.64523, 0.63795, 0.63847],\n",
       "       [0.63851, 0.6508 , 0.63784, 0.65068]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Test Data from the origin data\n",
    "ts_d = pd.read_csv(origin_data_save+product+'1440_Data.csv')\n",
    "# Change Header\n",
    "\n",
    "\n",
    "ts_d = ts_d.dropna(axis=0,how='any')\n",
    "ts_d = ts_d.drop(['Date','Year','Month','Day','Hour','Minute','Volume','RSI','MACD_M','MACD_S','STO_K','STO_D'],axis=1)\n",
    "# Minimize the first three days\n",
    "ts_d_len = len(ts_d) - window_size+1\n",
    "print(ts_d_len)\n",
    "# data.shape: (len(ts_w)*4*4) \n",
    "data = np.zeros((len(ts_d), window_size, LSTM_input_dim), dtype=float)\n",
    "\n",
    "ts_d_n = ts_d.iloc[:,:].values\n",
    "ts_d_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Loading........\n",
      "test_data: 399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.7176, 0.7138],\n",
       "        [0.7273, 0.7150],\n",
       "        [0.7295, 0.7246],\n",
       "        [0.7284, 0.7237],\n",
       "        [0.7250, 0.7243],\n",
       "        [0.7254, 0.7211],\n",
       "        [0.7265, 0.7194],\n",
       "        [0.7246, 0.7102],\n",
       "        [0.7117, 0.7089],\n",
       "        [0.7101, 0.7061],\n",
       "        [0.7108, 0.7082],\n",
       "        [0.7108, 0.7057],\n",
       "        [0.7108, 0.7054],\n",
       "        [0.7136, 0.7085],\n",
       "        [0.7132, 0.7072],\n",
       "        [0.7149, 0.7079],\n",
       "        [0.7148, 0.7134],\n",
       "        [0.7161, 0.7125],\n",
       "        [0.7174, 0.7104],\n",
       "        [0.7183, 0.7141],\n",
       "        [0.7207, 0.7071],\n",
       "        [0.7150, 0.7083],\n",
       "        [0.7158, 0.7131],\n",
       "        [0.7184, 0.7134],\n",
       "        [0.7199, 0.7142],\n",
       "        [0.7196, 0.7127],\n",
       "        [0.7167, 0.7090],\n",
       "        [0.7122, 0.7070],\n",
       "        [0.7107, 0.7093],\n",
       "        [0.7103, 0.7075],\n",
       "        [0.7097, 0.7059],\n",
       "        [0.7092, 0.7021],\n",
       "        [0.7052, 0.7005],\n",
       "        [0.7052, 0.7003],\n",
       "        [0.7042, 0.7031],\n",
       "        [0.7080, 0.7027],\n",
       "        [0.7092, 0.7057],\n",
       "        [0.7098, 0.7049],\n",
       "        [0.7097, 0.7041],\n",
       "        [0.7097, 0.7062],\n",
       "        [0.7088, 0.7080],\n",
       "        [0.7120, 0.7078],\n",
       "        [0.7111, 0.7085],\n",
       "        [0.7150, 0.7057],\n",
       "        [0.7168, 0.7090],\n",
       "        [0.7115, 0.7076],\n",
       "        [0.7083, 0.7076],\n",
       "        [0.7117, 0.7065],\n",
       "        [0.7148, 0.7108],\n",
       "        [0.7140, 0.7069],\n",
       "        [0.7106, 0.7064],\n",
       "        [0.7105, 0.7074],\n",
       "        [0.7117, 0.7105],\n",
       "        [0.7132, 0.7101],\n",
       "        [0.7129, 0.7053],\n",
       "        [0.7130, 0.7054],\n",
       "        [0.7127, 0.7098],\n",
       "        [0.7132, 0.7092],\n",
       "        [0.7109, 0.7102],\n",
       "        [0.7131, 0.7088],\n",
       "        [0.7152, 0.7120],\n",
       "        [0.7175, 0.7110],\n",
       "        [0.7170, 0.7117],\n",
       "        [0.7192, 0.7116],\n",
       "        [0.7179, 0.7170],\n",
       "        [0.7182, 0.7164],\n",
       "        [0.7179, 0.7140],\n",
       "        [0.7206, 0.7157],\n",
       "        [0.7199, 0.7137],\n",
       "        [0.7159, 0.7144],\n",
       "        [0.7153, 0.7143],\n",
       "        [0.7151, 0.7128],\n",
       "        [0.7139, 0.7081],\n",
       "        [0.7101, 0.7004],\n",
       "        [0.7023, 0.6988],\n",
       "        [0.7061, 0.7007],\n",
       "        [0.7044, 0.7036],\n",
       "        [0.7061, 0.7039],\n",
       "        [0.7069, 0.7031],\n",
       "        [0.7061, 0.7007],\n",
       "        [0.7029, 0.6995],\n",
       "        [0.7025, 0.6985],\n",
       "        [0.6998, 0.6970],\n",
       "        [0.7003, 0.6963],\n",
       "        [0.7048, 0.6981],\n",
       "        [0.7027, 0.6986],\n",
       "        [0.6998, 0.6965],\n",
       "        [0.7019, 0.6979],\n",
       "        [0.7002, 0.6988],\n",
       "        [0.6992, 0.6940],\n",
       "        [0.6959, 0.6935],\n",
       "        [0.6942, 0.6915],\n",
       "        [0.6933, 0.6887],\n",
       "        [0.6897, 0.6865],\n",
       "        [0.6903, 0.6890],\n",
       "        [0.6934, 0.6890],\n",
       "        [0.6929, 0.6866],\n",
       "        [0.6897, 0.6871],\n",
       "        [0.6904, 0.6865],\n",
       "        [0.6935, 0.6881],\n",
       "        [0.6933, 0.6927],\n",
       "        [0.6939, 0.6913],\n",
       "        [0.6936, 0.6916],\n",
       "        [0.6932, 0.6904],\n",
       "        [0.6937, 0.6899],\n",
       "        [0.6944, 0.6901],\n",
       "        [0.6938, 0.6928],\n",
       "        [0.6982, 0.6927],\n",
       "        [0.7004, 0.6956],\n",
       "        [0.7007, 0.6963],\n",
       "        [0.6994, 0.6964],\n",
       "        [0.7022, 0.6964],\n",
       "        [0.7007, 0.6994],\n",
       "        [0.6999, 0.6957],\n",
       "        [0.6967, 0.6947],\n",
       "        [0.6963, 0.6925],\n",
       "        [0.6939, 0.6901],\n",
       "        [0.6917, 0.6861],\n",
       "        [0.6876, 0.6871],\n",
       "        [0.6884, 0.6849],\n",
       "        [0.6882, 0.6832],\n",
       "        [0.6909, 0.6855],\n",
       "        [0.6936, 0.6880],\n",
       "        [0.6938, 0.6903],\n",
       "        [0.6936, 0.6929],\n",
       "        [0.6969, 0.6932],\n",
       "        [0.6978, 0.6942],\n",
       "        [0.6995, 0.6951],\n",
       "        [0.7009, 0.6984],\n",
       "        [0.7023, 0.6998],\n",
       "        [0.7035, 0.7025],\n",
       "        [0.7031, 0.6956],\n",
       "        [0.7000, 0.6960],\n",
       "        [0.7039, 0.6985],\n",
       "        [0.7048, 0.7016],\n",
       "        [0.7029, 0.6957],\n",
       "        [0.6983, 0.6973],\n",
       "        [0.6994, 0.6967],\n",
       "        [0.6975, 0.6921],\n",
       "        [0.6969, 0.6911],\n",
       "        [0.6988, 0.6954],\n",
       "        [0.7025, 0.6971],\n",
       "        [0.7023, 0.7013],\n",
       "        [0.7044, 0.7025],\n",
       "        [0.7043, 0.7010],\n",
       "        [0.7025, 0.6996],\n",
       "        [0.7082, 0.7006],\n",
       "        [0.7077, 0.7038],\n",
       "        [0.7047, 0.7040],\n",
       "        [0.7057, 0.7031],\n",
       "        [0.7035, 0.6996],\n",
       "        [0.7002, 0.6973],\n",
       "        [0.6984, 0.6942],\n",
       "        [0.6955, 0.6903],\n",
       "        [0.6913, 0.6906],\n",
       "        [0.6916, 0.6895],\n",
       "        [0.6908, 0.6869],\n",
       "        [0.6899, 0.6832],\n",
       "        [0.6868, 0.6795],\n",
       "        [0.6819, 0.6764],\n",
       "        [0.6796, 0.6789],\n",
       "        [0.6804, 0.6748],\n",
       "        [0.6801, 0.6753],\n",
       "        [0.6783, 0.6677],\n",
       "        [0.6822, 0.6748],\n",
       "        [0.6818, 0.6780],\n",
       "        [0.6785, 0.6780],\n",
       "        [0.6796, 0.6745],\n",
       "        [0.6818, 0.6747],\n",
       "        [0.6809, 0.6736],\n",
       "        [0.6789, 0.6747],\n",
       "        [0.6795, 0.6771],\n",
       "        [0.6787, 0.6778],\n",
       "        [0.6789, 0.6762],\n",
       "        [0.6795, 0.6755],\n",
       "        [0.6799, 0.6773],\n",
       "        [0.6787, 0.6751],\n",
       "        [0.6778, 0.6736],\n",
       "        [0.6741, 0.6690],\n",
       "        [0.6788, 0.6696],\n",
       "        [0.6777, 0.6747],\n",
       "        [0.6762, 0.6733],\n",
       "        [0.6753, 0.6717],\n",
       "        [0.6740, 0.6706],\n",
       "        [0.6730, 0.6723],\n",
       "        [0.6735, 0.6710],\n",
       "        [0.6764, 0.6688],\n",
       "        [0.6801, 0.6759],\n",
       "        [0.6830, 0.6794],\n",
       "        [0.6862, 0.6807],\n",
       "        [0.6849, 0.6840],\n",
       "        [0.6876, 0.6837],\n",
       "        [0.6870, 0.6849],\n",
       "        [0.6884, 0.6849],\n",
       "        [0.6895, 0.6860],\n",
       "        [0.6891, 0.6859],\n",
       "        [0.6881, 0.6864],\n",
       "        [0.6884, 0.6854],\n",
       "        [0.6869, 0.6830],\n",
       "        [0.6867, 0.6814],\n",
       "        [0.6828, 0.6780],\n",
       "        [0.6809, 0.6760],\n",
       "        [0.6772, 0.6765],\n",
       "        [0.6781, 0.6765],\n",
       "        [0.6806, 0.6765],\n",
       "        [0.6804, 0.6739],\n",
       "        [0.6781, 0.6746],\n",
       "        [0.6779, 0.6744],\n",
       "        [0.6766, 0.6757],\n",
       "        [0.6771, 0.6741],\n",
       "        [0.6775, 0.6672],\n",
       "        [0.6719, 0.6671],\n",
       "        [0.6753, 0.6702],\n",
       "        [0.6774, 0.6739],\n",
       "        [0.6764, 0.6756],\n",
       "        [0.6765, 0.6730],\n",
       "        [0.6757, 0.6723],\n",
       "        [0.6750, 0.6712],\n",
       "        [0.6775, 0.6710],\n",
       "        [0.6811, 0.6759],\n",
       "        [0.6798, 0.6788],\n",
       "        [0.6801, 0.6751],\n",
       "        [0.6789, 0.6743],\n",
       "        [0.6766, 0.6724],\n",
       "        [0.6833, 0.6753],\n",
       "        [0.6857, 0.6821],\n",
       "        [0.6855, 0.6840],\n",
       "        [0.6880, 0.6845],\n",
       "        [0.6883, 0.6850],\n",
       "        [0.6862, 0.6834],\n",
       "        [0.6858, 0.6811],\n",
       "        [0.6836, 0.6809],\n",
       "        [0.6826, 0.6817],\n",
       "        [0.6845, 0.6811],\n",
       "        [0.6872, 0.6836],\n",
       "        [0.6902, 0.6849],\n",
       "        [0.6930, 0.6883],\n",
       "        [0.6921, 0.6884],\n",
       "        [0.6915, 0.6907],\n",
       "        [0.6925, 0.6877],\n",
       "        [0.6928, 0.6877],\n",
       "        [0.6907, 0.6869],\n",
       "        [0.6913, 0.6862],\n",
       "        [0.6906, 0.6848],\n",
       "        [0.6861, 0.6855],\n",
       "        [0.6865, 0.6845],\n",
       "        [0.6857, 0.6831],\n",
       "        [0.6857, 0.6821],\n",
       "        [0.6841, 0.6770],\n",
       "        [0.6821, 0.6781],\n",
       "        [0.6817, 0.6811],\n",
       "        [0.6822, 0.6799],\n",
       "        [0.6835, 0.6785],\n",
       "        [0.6831, 0.6790],\n",
       "        [0.6814, 0.6783],\n",
       "        [0.6803, 0.6780],\n",
       "        [0.6792, 0.6787],\n",
       "        [0.6799, 0.6768],\n",
       "        [0.6795, 0.6768],\n",
       "        [0.6791, 0.6759],\n",
       "        [0.6774, 0.6762],\n",
       "        [0.6780, 0.6754],\n",
       "        [0.6768, 0.6762],\n",
       "        [0.6826, 0.6764],\n",
       "        [0.6862, 0.6816],\n",
       "        [0.6855, 0.6813],\n",
       "        [0.6855, 0.6821],\n",
       "        [0.6857, 0.6824],\n",
       "        [0.6838, 0.6831],\n",
       "        [0.6836, 0.6818],\n",
       "        [0.6837, 0.6800],\n",
       "        [0.6889, 0.6804],\n",
       "        [0.6938, 0.6870],\n",
       "        [0.6929, 0.6864],\n",
       "        [0.6883, 0.6870],\n",
       "        [0.6898, 0.6868],\n",
       "        [0.6877, 0.6838],\n",
       "        [0.6864, 0.6839],\n",
       "        [0.6891, 0.6854],\n",
       "        [0.6907, 0.6884],\n",
       "        [0.6906, 0.6891],\n",
       "        [0.6929, 0.6897],\n",
       "        [0.6930, 0.6912],\n",
       "        [0.6926, 0.6917],\n",
       "        [0.6950, 0.6922],\n",
       "        [0.6987, 0.6943],\n",
       "        [0.6989, 0.6978],\n",
       "        [0.7004, 0.6982],\n",
       "        [0.7032, 0.6999],\n",
       "        [0.7020, 0.7005],\n",
       "        [0.7020, 0.6979],\n",
       "        [0.6987, 0.6930],\n",
       "        [0.6945, 0.6933],\n",
       "        [0.6958, 0.6925],\n",
       "        [0.6939, 0.6850],\n",
       "        [0.6886, 0.6849],\n",
       "        [0.6881, 0.6850],\n",
       "        [0.6911, 0.6851],\n",
       "        [0.6906, 0.6893],\n",
       "        [0.6920, 0.6895],\n",
       "        [0.6910, 0.6885],\n",
       "        [0.6917, 0.6877],\n",
       "        [0.6934, 0.6888],\n",
       "        [0.6911, 0.6870],\n",
       "        [0.6883, 0.6872],\n",
       "        [0.6888, 0.6855],\n",
       "        [0.6880, 0.6842],\n",
       "        [0.6856, 0.6827],\n",
       "        [0.6879, 0.6829],\n",
       "        [0.6857, 0.6818],\n",
       "        [0.6818, 0.6801],\n",
       "        [0.6817, 0.6752],\n",
       "        [0.6767, 0.6737],\n",
       "        [0.6777, 0.6735],\n",
       "        [0.6753, 0.6700],\n",
       "        [0.6730, 0.6683],\n",
       "        [0.6696, 0.6684],\n",
       "        [0.6707, 0.6684],\n",
       "        [0.6742, 0.6679],\n",
       "        [0.6774, 0.6724],\n",
       "        [0.6765, 0.6727],\n",
       "        [0.6731, 0.6662],\n",
       "        [0.6678, 0.6667],\n",
       "        [0.6707, 0.6668],\n",
       "        [0.6737, 0.6681],\n",
       "        [0.6750, 0.6707],\n",
       "        [0.6745, 0.6710],\n",
       "        [0.6731, 0.6709],\n",
       "        [0.6730, 0.6717],\n",
       "        [0.6733, 0.6707],\n",
       "        [0.6710, 0.6674],\n",
       "        [0.6708, 0.6665],\n",
       "        [0.6694, 0.6610],\n",
       "        [0.6639, 0.6586],\n",
       "        [0.6609, 0.6591],\n",
       "        [0.6620, 0.6587],\n",
       "        [0.6622, 0.6586],\n",
       "        [0.6607, 0.6542],\n",
       "        [0.6592, 0.6543],\n",
       "        [0.6585, 0.6434],\n",
       "        [0.6525, 0.6472],\n",
       "        [0.6568, 0.6489],\n",
       "        [0.6645, 0.6510],\n",
       "        [0.6629, 0.6584],\n",
       "        [0.6637, 0.6584],\n",
       "        [0.6657, 0.6585],\n",
       "        [0.6623, 0.6593],\n",
       "        [0.6685, 0.6315],\n",
       "        [0.6608, 0.6463],\n",
       "        [0.6539, 0.6473],\n",
       "        [0.6487, 0.6212],\n",
       "        [0.6325, 0.6123],\n",
       "        [0.6302, 0.6106],\n",
       "        [0.6218, 0.6079],\n",
       "        [0.6149, 0.5959],\n",
       "        [0.6029, 0.5701],\n",
       "        [0.5964, 0.5509],\n",
       "        [0.5985, 0.5668],\n",
       "        [0.5825, 0.5705],\n",
       "        [0.5846, 0.5700],\n",
       "        [0.5990, 0.5827],\n",
       "        [0.6073, 0.5894],\n",
       "        [0.6087, 0.5870],\n",
       "        [0.6200, 0.6022],\n",
       "        [0.6155, 0.6113],\n",
       "        [0.6184, 0.6112],\n",
       "        [0.6213, 0.6072],\n",
       "        [0.6184, 0.6038],\n",
       "        [0.6119, 0.6007],\n",
       "        [0.6075, 0.5980],\n",
       "        [0.6015, 0.5995],\n",
       "        [0.6106, 0.5990],\n",
       "        [0.6207, 0.6080],\n",
       "        [0.6244, 0.6115],\n",
       "        [0.6363, 0.6195],\n",
       "        [0.6367, 0.6312],\n",
       "        [0.6358, 0.6325],\n",
       "        [0.6409, 0.6329],\n",
       "        [0.6444, 0.6374],\n",
       "        [0.6441, 0.6284],\n",
       "        [0.6370, 0.6264],\n",
       "        [0.6385, 0.6314],\n",
       "        [0.6366, 0.6346],\n",
       "        [0.6397, 0.6330],\n",
       "        [0.6346, 0.6253],\n",
       "        [0.6352, 0.6280],\n",
       "        [0.6406, 0.6282],\n",
       "        [0.6396, 0.6337],\n",
       "        [0.6394, 0.6378],\n",
       "        [0.6471, 0.6387],\n",
       "        [0.6513, 0.6434],\n",
       "        [0.6558, 0.6491],\n",
       "        [0.6569, 0.6483],\n",
       "        [0.6498, 0.6410],\n",
       "        [0.6411, 0.6379],\n",
       "        [0.6434, 0.6372],\n",
       "        [0.6475, 0.6416],\n",
       "        [0.6452, 0.6380],\n",
       "        [0.6508, 0.6378]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Test set\n",
    "for i in range(0, ts_d_len):\n",
    "    # Generate 4*4 temporary array\n",
    "    temp = np.zeros((window_size, LSTM_input_dim))\n",
    "    for j in range(i, i+window_size):\n",
    "        # i=0, j=0,1,2,3 \n",
    "        temp[j-i]=ts_d_n[j]\n",
    "    # Fill data array\n",
    "    data[i] = temp\n",
    "train_num = math.ceil(train_ratio*ts_d_len)\n",
    "test_num = ts_d_len-train_num\n",
    "\n",
    "test_data = data[train_num: ts_d_len]\n",
    "\n",
    "test_X = np.zeros((test_num, window_size-pred_days, LSTM_input_dim), dtype=float)\n",
    "test_Y = np.zeros((test_num, LSTM_output_dim), dtype=float)\n",
    "\n",
    "for i in range(test_num):\n",
    "    test_X[i] = test_data[i][0:window_size-1]\n",
    "    for j in range(LSTM_output_dim):\n",
    "        test_Y[i][j] = test_data[i][window_size-1][j+1]\n",
    "\n",
    "\n",
    "test_X = torch.tensor(test_X,dtype=torch.float32).cuda()\n",
    "test_Y = torch.tensor(test_Y,dtype=torch.float32).cuda()\n",
    "\n",
    "print('Finish Loading........')\n",
    "print('test_data:',test_num)\n",
    "test_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module): # extend nn.Module\n",
    "    # Define the LSTM network\n",
    "    def __init__(self,input_size,hidden_size, output_size=LSTM_output_dim,num_layers=2):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size,hidden_size,num_layers)\n",
    "        self.linear = nn.Linear(hidden_size*(window_size-pred_days),output_size)\n",
    "        self.batch_first = True\n",
    "    \n",
    "    def forward(self,x): # x: input\n",
    "        # Only get the resultï¼Œ no hidden state\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # get the index of hidden state\n",
    "        batch_n,win_s,hidden_s = lstm_out.shape\n",
    "        # Flatten to 2D: s*b rows and h cols\n",
    "        linear_in = lstm_out.view(batch_n, win_s*hidden_s)\n",
    "        out = self.linear(linear_in)\n",
    "        output = out.view(batch_n,2)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(4, 64, num_layers=2)\n",
      "  (linear): Linear(in_features=192, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(input_size=LSTM_input_dim, hidden_size=n_hidden_size).cuda()\n",
    "print(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=LR)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSELoss(yhat,y):\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2))\n",
    "\n",
    "def train_model(train_X, save_model_name):\n",
    "    losses = []\n",
    "    losses2 = []\n",
    "    print(\"Training Start. Epochs = \", EPOCH)\n",
    "    for i in range(EPOCH):\n",
    "        output = lstm(train_X)\n",
    "        loss = loss_function(output, train_Y)\n",
    "        loss2 = RMSELoss(output,train_Y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        losses2.append(loss2.item())\n",
    "        if (i+1) % 50 == 0:\n",
    "            print('Epoch:',i+1,'Loss:', loss.item())\n",
    "            \n",
    "    torch.save(lstm, model_save+save_model_name)\n",
    "    return loss.item(), losses,loss2.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_name, test_X):\n",
    "    # Load the trained model\n",
    "    lstm64 = torch.load(model_save+model_name)\n",
    "    # Forward the test data\n",
    "    test_output = lstm64.forward(test_X)\n",
    "    # Calculate the loss\n",
    "    loss = loss_function(test_output, test_Y)\n",
    "    loss2 = RMSELoss(test_output,test_Y)\n",
    "    return test_output, loss.item(),loss2.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    model_name=product+'.pkl'\n",
    "    train_MSE, losses, train_RMSE = train_model(train_X, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE  2.9288774385349825e-05 ;test MSE; 0.00010366209608037025 ;Train RMSE; 0.005411910358816385 Test RMSE 0.010181458666920662\n"
     ]
    }
   ],
   "source": [
    "test_output, test_MSE, test_RMSE = test_model(model_name, test_X)\n",
    "\n",
    "print(\"Train MSE \", train_MSE,\";test MSE;\", test_MSE,\";Train RMSE;\",train_RMSE,\"Test RMSE\",test_RMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_output, _, _ = test_model(model_name, test_X)\n",
    "test_output_plot = test_output.cpu().detach().numpy()\n",
    "test_y_plot = test_Y.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(test_output_plot)\n",
    "out.to_csv('TS_data_Pred//'+product+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
